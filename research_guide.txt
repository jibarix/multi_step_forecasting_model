# Multi-Step Forecasting with Dynamic Anchor Variables in Retail

## Background  
Multi-step time-series forecasting involves predicting multiple future points (e.g. next 6 months of sales) rather than a single step ahead. Incorporating **dynamic anchor variables** means including time-varying external or auxiliary inputs that “anchor” the forecast trajectory – for example, known future events, policy targets, or promotional plans that can guide the model. In retail forecasting, these anchors might include promotional calendars, holidays, economic indicators, or high-frequency sales signals. Recent work in both academic and government research has focused on improving multi-step forecasts by leveraging such dynamic variables, while addressing challenges in methodology and validation.

Retail demand forecasting is particularly challenging due to the multitude of factors influencing sales (price promotions, seasonality, store traffic, etc.) and the high dimensionality of data. A comprehensive review of retail forecasting notes that promotional information and other factors add considerable complexity – forecasters often face **“too many variables and too little data”** when building models ([Retail forecasting: Research and practice](https://ideas.repec.org/a/eee/intfor/v38y2022i4p1283-1318.html#:~:text=This%20paper%20reviews%20the%20research,evaluate%20evidence%20on%20comparative%20forecasting)). This review found that traditional *causal* models (e.g. regression models with predictors like price, promotions) generally outperform naive benchmarks, highlighting the value of incorporating domain factors. However, as of that study, evidence on the benefits of more complex machine learning methods in retail was still emerging ([Retail forecasting: Research and practice](https://ideas.repec.org/a/eee/intfor/v38y2022i4p1283-1318.html#:~:text=promotional%20information%2C%20add%20considerable%20complexity%2C,and%20barriers%20to%20improved%20practice)). In recent years (2019–2024), numerous studies have attempted to fill this gap, proposing advanced models and techniques for multi-step forecasting with dynamic anchors, and evaluating them on retail case studies.

## Institutional Approaches: Anchoring Forecasts with External Information  
Government economic research institutions and central banks have explored using anchor variables to improve forecasts, often in the context of **macro-economic or sectoral prediction**. A notable example comes from the **Banco Central do Brasil**, where researchers incorporated survey-based expectations to anchor the long-term projections of an inflation forecast model. They extended the “shifting endpoint” approach (originally a univariate method) to a multivariate VAR model with exogenous inputs ([](https://www.bcb.gov.br/pec/wps/ingl/wps574.pdf#:~:text=In%20this%20paper%2C%20we%20generalize,Our%20goal%20is%20to%20propose)). Essentially, the model’s long-horizon forecasts are continuously corrected toward the survey-implied target (the anchor) using state-space methods. This **dynamic anchoring** allowed the multi-step-ahead forecasts to quickly adjust as new survey information became available, significantly improving accuracy at longer horizons ([](https://www.bcb.gov.br/pec/wps/ingl/wps574.pdf#:~:text=quickly%20adapt%20the%20multi,indicate%20forecasts%20obtained%20from%20the)). An empirical evaluation on Brazilian data showed that the anchored VAR outperformed traditional backward-looking methods in predicting inflation, especially for persistent trends ([](https://www.bcb.gov.br/pec/wps/ingl/wps574.pdf#:~:text=quickly%20adapt%20the%20multi,indicate%20forecasts%20obtained%20from%20the)). The key takeaway is that **forward-looking anchors** (like surveys of expectations or policy targets) can materially reduce long-run forecast bias and error, though performance can still be challenged by extreme events (e.g. the model’s error rose during the COVID-19 shock when usual dynamics broke down) ([](https://www.bcb.gov.br/pec/wps/ingl/wps574.pdf#:~:text=econ%02omy%20in%20recent%20years%2C%20such,using%20VARs%20and%20survey%20data)).

Focusing on the retail sector specifically, government researchers have leveraged **high-frequency data as dynamic anchors** to improve official retail sales forecasts. For instance, the Federal Reserve Bank of **Chicago** developed a weekly index of retail trade by combining multiple rapid data sources – credit/debit card transactions, foot traffic measures, gasoline sales, and consumer sentiment ([Tracking U.S. Consumers in Real Time with a New Weekly Index of Retail Trade;](https://www.chicagofed.org/~/media/publications/working-papers/2021/wp2021-05-pdf.pdf#:~:text=construct%20the%20index%2C%20we%20extract,the%20index%20to%20document%20several)). They used a **mixed-frequency dynamic factor model** to blend these high-frequency indicators and constrain them to be consistent with the monthly retail sales figures from the Census (the official series). In effect, the weekly index is anchored to the monthly total through a statistical benchmarking process ([Tracking U.S. Consumers in Real Time with a New Weekly Index of Retail Trade;](https://www.chicagofed.org/~/media/publications/working-papers/2021/wp2021-05-pdf.pdf#:~:text=ensure%20that%20the%20index%20is,the%20index%20to%20document%20several)). This approach, called the Chicago Fed Advance Retail Trade Summary (**CARTS**), provided an early snapshot of consumer spending and was particularly valuable during the volatile COVID-19 period. The validation showed strong results: the weekly index could have **predicted the official Monthly Retail Trade Survey more accurately in real-time** than either consensus forecasts or pure time-series models. In fact, during the pandemic, the anchored weekly model reduced mean absolute forecast errors by over **50%** compared to benchmarks ([Tracking U.S. Consumers in Real Time with a New Weekly Index of Retail Trade;](https://www.chicagofed.org/~/media/publications/working-papers/2021/wp2021-05-pdf.pdf#:~:text=are%20not%20visible%20in%20the,in%20mean%20absolute%20forecast%20errors)). This case study demonstrates how dynamic, high-frequency anchors (like card transaction data) can bolster multi-step retail forecasts, allowing policymakers and businesses to react faster to sudden changes in consumer behavior.

*(Other central banks and organizations have similarly explored anchored forecasting. For example, Bank of England analysts used daily card payment data (CHAPS) as anchors to nowcast UK consumer spending. These initiatives underscore a trend: integrating timely “big data” indicators via formal models to improve multi-step forecasts of retail or consumption activity.)*

## Academic Methodologies for Multi-Step Forecasting  
Academic research in the last five years has introduced a range of **methodologies** to handle multi-step forecasting with dynamic variables, often motivated by retail or inventory management applications. These methodologies include extensions of classical models as well as novel machine learning and deep learning approaches:

- **Extended ARIMA/State-Space Models**: Traditional statistical models like ARIMA have been extended to ARIMAX or state-space frameworks to include exogenous regressors (e.g. promotions, economic indicators). Techniques such as hierarchical forecasting (for product-store hierarchies) and *shifting endpoints* (as in the BCB study) are used to enforce long-term anchors or aggregate consistency. These models often rely on domain knowledge to select anchor variables and can incorporate them fairly transparently. The retail forecasting literature confirms that such causal models tend to beat simplistic approaches, provided relevant predictors (e.g. price, marketing events) are included ([Retail forecasting: Research and practice](https://ideas.repec.org/a/eee/intfor/v38y2022i4p1283-1318.html#:~:text=promotional%20information%2C%20add%20considerable%20complexity%2C,to%20both%20research%20gaps%20and)).

- **Machine Learning Ensembles**: There has been a surge in tree-based and ensemble methods for retail forecasting. A landmark study is the **M5 Forecasting Competition** (2020), which was a public competition focused on multi-step **retail sales forecasting** (using a Walmart dataset). The results, published in 2021, showed a clear dominance of machine learning methods over traditional time-series models ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=in%20the%20M5%20all%2050,implementations%2C%20showed%20potential%20for%20further)) ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=combinations,33)). In particular, gradient boosting machines (such as **LightGBM**) achieved superior accuracy in predicting 28-day ahead product sales across thousands of store-item combinations ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=%E2%80%A2%20The%20superior%20accuracy%20of,accuracy%20of%20time%20series%20methods)). These models excelled by handling large numbers of related time series and incorporating many exogenous variables (holiday flags, price changes, etc.). A key finding was the **importance of exogenous/explanatory variables** for improving forecast accuracy ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=forecasting%20accuracy%20of%20the%20baseline,forecasting%20accuracy%20of%20time%20series)) – models that effectively used the provided calendar and price/promotional information performed much better than those that relied purely on past sales. Moreover, the top submissions in M5 often employed **ensemble techniques** (averaging multiple models) and **feature engineering** to capture complex patterns ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=combinations,33)). The competition’s organizers noted three best practices reaffirmed by M5’s outcome: combining forecasts from different models, leveraging “**cross-learning**” (training on many related time series together to share information), and using extensive **cross-validation** for robust model tuning ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=In%20addition%2C%20M5%20reaffirms%20the,validation)). These practices helped address the variability and uncertainty inherent in multi-step retail forecasts.

- **Deep Learning Models**: Building on advances in sequence modeling, researchers have developed deep neural networks specifically for multi-step (multi-horizon) forecasting. One prominent example is the **Temporal Fusion Transformer (TFT)** by Lim et al. (2021) ([Temporal Fusion Transformers for interpretable multi-horizon time series forecasting](https://ideas.repec.org/a/eee/intfor/v37y2021i4p1748-1764.html#:~:text=In%20this%20paper%2C%20we%20introduce,interpretability%20use%20cases%20of%20TFT)). The TFT is an attention-based neural network designed to integrate multiple types of inputs: it can handle **static covariates** (e.g. store type), **known future inputs** (e.g. a planned promotion or holiday indicator, which is a dynamic anchor known in advance), and **observed history** (past sales and lags) simultaneously ([Temporal Fusion Transformers for interpretable multi-horizon time series forecasting](https://ideas.repec.org/a/eee/intfor/v37y2021i4p1748-1764.html#:~:text=Multi,To%20learn)). The architecture includes gating and variable selection components that allow it to **focus on the most relevant features** at each time step, essentially learning which anchor variables matter most for the forecast ([Interpretable Deep Learning for Time Series Forecasting ](https://research.google/blog/interpretable-deep-learning-for-time-series-forecasting/#:~:text=wide%20range%20of%20datasets,have%20different%20temporal%20dynamics%20for)) ([Interpretable Deep Learning for Time Series Forecasting ](https://research.google/blog/interpretable-deep-learning-for-time-series-forecasting/#:~:text=step,daily%20peaks%20after%20working%20hours)). It also uses a hybrid of recurrent layers and self-attention layers to capture short-term sequences and long-term patterns. In evaluations on several real-world datasets (electricity demand, traffic, volatility, and a retail dataset), TFT delivered **significant performance improvements over classical models (ARIMA, ETS) and earlier deep learning models** ([Interpretable Deep Learning for Time Series Forecasting ](https://research.google/blog/interpretable-deep-learning-for-time-series-forecasting/#:~:text=healthcare%20institutions%20can%20use%20the,have%20sufficient%20personnel%20and%20equipment)) ([Interpretable Deep Learning for Time Series Forecasting ](https://research.google/blog/interpretable-deep-learning-for-time-series-forecasting/#:~:text=Deep%20neural%20networks%20,not%20consider%20the%20different%20inputs)). An attractive aspect of such models is their **interpretability**: TFT, for instance, can output attention weights and importance scores indicating which covariates (anchors) were most influential for a given forecast, helping analysts trust and understand the predictions ([Temporal Fusion Transformers for interpretable multi-horizon time series forecasting](https://ideas.repec.org/a/eee/intfor/v37y2021i4p1748-1764.html#:~:text=temporal%20relationships%20at%20different%20scales%2C,interpretability%20use%20cases%20of%20TFT)). Apart from TFT, other deep learning approaches like recurrent neural networks (e.g. Amazon’s DeepAR) and convolutional or transformer-based models have been applied to retail forecasting, often allowing **multi-step prediction in one model run (direct multi-output)** rather than forecasting iteratively. These models naturally accommodate dynamic variables by feeding them as additional input features at each time step.

- **Hybrid and Two-Stage Models**: Some research has looked at combining statistical models with ML in a two-stage process. For example, a fashion retail forecasting study proposed first forecasting baseline demand and then adjusting via a machine learning model for residuals and local factors (to account for dynamic influences). Such hybrid approaches aim to capture the best of both worlds: the interpretable global structure of statistical forecasts with the flexibility of ML to learn nonlinear effects of anchor variables (like weather or social media trends). While promising, these tend to be case-specific and require careful tuning. *(Specific case studies from the last five years in this vein include applications in fashion and fast-moving consumer goods, though the core ideas overlap with the methods above.)*

## Validation Techniques and Case Studies  
Ensuring the reliability of multi-step forecasts is crucial, given that errors can compound over the forecast horizon. Researchers have employed several **validation techniques** to assess and improve models that use dynamic anchors:

- **Out-of-Sample Testing**: Most studies conduct rolling **out-of-sample forecasts** to evaluate performance. For instance, the M5 competition used a held-out test period (the final 28 days of sales) to compare forecast accuracy of all methods under identical conditions ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=This%20paper%20describes%20the%20M5,focusing%20on%20series%20that%20display)) ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=and%20practice%20of%20forecasting,the%20competition%2C%20its%20results%2C%20the)). Similarly, academic papers often use a rolling origin evaluation – forecasting multiple steps ahead from various historical cutoff points and comparing to actual outcomes – to gauge how models perform in different conditions. The **error metrics** vary by context: M5 focused on a weighted RMSE (reflecting item and hierarchy importance), while others use MAE, MAPE, or MASE to measure multi-step accuracy. A consistent finding is that models leveraging anchor variables maintain an accuracy edge across forecast horizons, especially evident in aggregate error reductions (e.g. the Chicago Fed’s anchored model cut MAE by half during COVID ([Tracking U.S. Consumers in Real Time with a New Weekly Index of Retail Trade;](https://www.chicagofed.org/~/media/publications/working-papers/2021/wp2021-05-pdf.pdf#:~:text=are%20not%20visible%20in%20the,in%20mean%20absolute%20forecast%20errors))).

- **Cross-Validation and Hyperparameter Tuning**: Time-series cross-validation (a form of k-fold that respects temporal order) is widely used to tune model parameters when anchor variables are in play. Because introducing many dynamic features risks overfitting, researchers emphasize rigorous cross-validation. The M5 findings explicitly highlighted the value of **cross-validation** in selecting models that generalize well ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=In%20addition%2C%20M5%20reaffirms%20the,validation)). Many top-performing approaches (including ensembles and deep learning models) underwent extensive hyperparameter searches and back-testing on multiple folds or simulation of pseudo out-of-sample scenarios to ensure their multi-step forecasts don’t just hindsight-fit the training data.

- **Benchmarking Against Alternatives**: Validation often involves comparing the anchored model to simpler or established benchmarks. In the **Chicago Fed’s** retail index study, the weekly dynamic factor model was benchmarked against consensus economist forecasts and a basic monthly autoregressive model ([Tracking U.S. Consumers in Real Time with a New Weekly Index of Retail Trade;](https://www.chicagofed.org/~/media/publications/working-papers/2021/wp2021-05-pdf.pdf#:~:text=are%20not%20visible%20in%20the,cited)). By showing the anchored model’s superior tracking of actual retail sales (especially during turning points), the researchers built confidence in the method’s practical value. Likewise, central bank studies (e.g. BCB) compare anchored VAR forecasts to unanchored versions or to survey predictions alone, demonstrating improvements at various horizons ([](https://www.bcb.gov.br/pec/wps/ingl/wps574.pdf#:~:text=quickly%20adapt%20the%20multi,indicate%20forecasts%20obtained%20from%20the)). This kind of **horse-race evaluation** is a standard validation technique in forecasting research to quantify the gain from adding anchor variables.

- **Case Study Simulations**: Some validations are scenario-based. For example, researchers might back-test how their model would have performed during a **stress event** (like the 2020 pandemic or a major demand shock). The BCB paper did a split-sample analysis: using a pre-COVID sample to establish baseline performance, then examining forecast errors when the pandemic hit (where models faced data far outside typical ranges) ([](https://www.bcb.gov.br/pec/wps/ingl/wps574.pdf#:~:text=econ%02omy%20in%20recent%20years%2C%20such,using%20VARs%20and%20survey%20data)). This revealed how robust the anchoring approach was under extreme conditions. In retail contexts, a case study might involve a particular promotion period or new product launch – the model’s multi-step predictions during these events are scrutinized to ensure it properly utilized anchors (e.g. a promotion flag should lead to a predicted uplift in sales). Such **case-study validations** provide qualitative insight into whether the model behaves as expected in real business scenarios.

- **Hierarchical and Group-Level Validation**: In retail, forecasts are often needed at multiple levels (item-store, category, region, total). Validation therefore also checks consistency and accuracy across aggregation levels. Methods like the ones in M5 had to forecast a hierarchy of time series. A successful model not only produces low error at the granular level, but also yields coherent forecasts that aggregate correctly (or are reconciled). Techniques like bottom-up or top-down reconciliation can be part of the forecasting process, but their effectiveness is evaluated by how much they improve the overall accuracy. The M5 competition results noted that a combination of top-down and bottom-up reconciliation performed best among simple methods, though the pure ML models ultimately led the field ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=match%20at%20L1742%201993%29,forecasts%20derived%20by%20the%20ML)). This underscores that validation isn’t just about single-series accuracy – **structural consistency** is also tested.

## Key Findings and Insights  
Recent research on multi-step retail forecasting with dynamic anchors has yielded several important insights and best practices:

- **Dynamic anchors improve accuracy**: Incorporating relevant external variables (anchors) consistently helps forecasts. Whether it’s using survey expectations to pin down long-run trends ([](https://www.bcb.gov.br/pec/wps/ingl/wps574.pdf#:~:text=quickly%20adapt%20the%20multi,indicate%20forecasts%20obtained%20from%20the)) or adding holiday and promotion indicators to retail models, anchored approaches outperform purely historical models at multiple horizons. The M5 competition, for example, demonstrated that including exogenous variables led to substantial accuracy gains in retail sales prediction ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=forecasting%20accuracy%20of%20the%20baseline,forecasting%20accuracy%20of%20time%20series)).

- **Methodologies are evolving**: Traditional statistical models (VAR, ARIMAX, etc.) have been augmented by modern ML and deep learning techniques. Ensemble tree-based models (like LightGBM) and neural networks (like TFT, DeepAR) can automatically handle complex interactions of many features and have now proven their capability on large-scale retail data ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=in%20the%20M5%20all%2050,implementations%2C%20showed%20potential%20for%20further)) ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=combinations,33)). These models often require more data and computation, but they excel at multi-step forecasts especially when patterns are nonlinear or vary by context.

- **Importance of interpretability and dimensionality reduction**: With many anchor variables, there is a risk of overfitting or losing insight. Techniques such as **variable selection (feature importance)** in ensembles, **attention mechanisms** in TFT ([Interpretable Deep Learning for Time Series Forecasting ](https://research.google/blog/interpretable-deep-learning-for-time-series-forecasting/#:~:text=wide%20range%20of%20datasets,have%20different%20temporal%20dynamics%20for)) ([Interpretable Deep Learning for Time Series Forecasting ](https://research.google/blog/interpretable-deep-learning-for-time-series-forecasting/#:~:text=step,daily%20peaks%20after%20working%20hours)), or simply expert judgment to select which anchors to include, are crucial. The academic literature emphasizes interpretability – for instance, being able to explain how a promotion or economic indicator affected the forecast – as key for adoption in practice. Thus, models that provide **transparent contributions of anchor variables** are preferred in operational settings.

- **Robust validation is key**: Given the additional complexity of models with dynamic inputs, validation techniques (rolling backtests, cross-validation, benchmarking) are especially important. Studies uniformly stress testing models on multiple scenarios and avoiding reliance on a single train/test split. The use of **cross-learning** (training on many related series) in competitions and practice helps models generalize better ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=In%20addition%2C%20M5%20reaffirms%20the,validation)). Additionally, **combining forecasts** from different models can hedge against the weaknesses of any one approach – this was evident in M5 and remains a recommended practice ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=In%20addition%2C%20M5%20reaffirms%20the,validation)).

- **Real-world impact**: Case studies show that these advanced forecasting models can have tangible benefits for retailers and policymakers. For retail businesses, more accurate multi-step forecasts (e.g. for demand planning) mean better inventory allocation, fewer stockouts or overstocks, and improved financial performance. For example, Walmart’s data in M5 showed that machine learning models could markedly improve daily SKU-level predictions ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=%E2%80%A2%20The%20superior%20accuracy%20of,accuracy%20of%20time%20series%20methods)), which in practice translates to more efficient supply chain decisions. On the policy side, tools like the Chicago Fed’s CARTS index have given decision-makers a **faster read on consumer spending**, enabling timely interventions. In summary, the incorporation of dynamic anchor variables in forecasting models – coupled with rigorous methodology and validation – has advanced the state of retail forecasting, though continued research is addressing remaining gaps (such as new product forecasting and adapting models to structural breaks). 

**Sources:** Recent literature and institutional reports provide the basis for these insights. Key references include a 2022 review of retail forecasting research ([Retail forecasting: Research and practice](https://ideas.repec.org/a/eee/intfor/v38y2022i4p1283-1318.html#:~:text=This%20paper%20reviews%20the%20research,evaluate%20evidence%20on%20comparative%20forecasting)) ([Retail forecasting: Research and practice](https://ideas.repec.org/a/eee/intfor/v38y2022i4p1283-1318.html#:~:text=promotional%20information%2C%20add%20considerable%20complexity%2C,and%20barriers%20to%20improved%20practice)), results of the M5 forecasting competition led by Makridakis et al. ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=%E2%80%A2%20The%20superior%20accuracy%20of,accuracy%20of%20time%20series%20methods)) ([](https://statmodeling.stat.columbia.edu/wp-content/uploads/2021/10/M5_accuracy_competition.pdf#:~:text=In%20addition%2C%20M5%20reaffirms%20the,validation)), the Temporal Fusion Transformer study by Lim et al. (IJF, 2021) ([Temporal Fusion Transformers for interpretable multi-horizon time series forecasting](https://ideas.repec.org/a/eee/intfor/v37y2021i4p1748-1764.html#:~:text=Multi,To%20learn)) ([Temporal Fusion Transformers for interpretable multi-horizon time series forecasting](https://ideas.repec.org/a/eee/intfor/v37y2021i4p1748-1764.html#:~:text=temporal%20relationships%20at%20different%20scales%2C,interpretability%20use%20cases%20of%20TFT)), and applied research from central banks (e.g. Banco Central do Brasil on anchoring forecasts ([](https://www.bcb.gov.br/pec/wps/ingl/wps574.pdf#:~:text=quickly%20adapt%20the%20multi,indicate%20forecasts%20obtained%20from%20the)) and the Chicago Fed’s high-frequency retail index ([Tracking U.S. Consumers in Real Time with a New Weekly Index of Retail Trade;](https://www.chicagofed.org/~/media/publications/working-papers/2021/wp2021-05-pdf.pdf#:~:text=construct%20the%20index%2C%20we%20extract,the%20index%20to%20document%20several)) ([Tracking U.S. Consumers in Real Time with a New Weekly Index of Retail Trade;](https://www.chicagofed.org/~/media/publications/working-papers/2021/wp2021-05-pdf.pdf#:~:text=are%20not%20visible%20in%20the,in%20mean%20absolute%20forecast%20errors))). These works collectively highlight how multi-step forecasting models with dynamic anchors are developed and validated, and how they perform in retail contexts. Each case reinforces that blending time-series models with judicious use of external information can greatly enhance forecast performance in the retail sector.